{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import nltk\r\n",
    "import json\r\n",
    "import numpy as np\r\n",
    "from keras.utils import np_utils\r\n",
    "from keras.preprocessing.text import Tokenizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# LPH = Label, Premise, Hypothesis\r\n",
    "def getLPH(fileName):\r\n",
    "  l = []\r\n",
    "  for _, line in enumerate(open(fileName)):\r\n",
    "    jsonData = json.loads(line)\r\n",
    "    label = jsonData['gold_label']\r\n",
    "    getToks = lambda s: ' '.join(s.replace('(', ' ').replace(')', ' ').replace('-LRB-', '(').replace('-RRB-', ')').split())\r\n",
    "    print(getToks)\r\n",
    "    p = getToks(jsonData['sentence1_binary_parse'])\r\n",
    "    h = getToks(jsonData['sentence2_binary_parse'])\r\n",
    "    # no majority among turks\r\n",
    "    if label == '-':\r\n",
    "      continue\r\n",
    "\r\n",
    "    l.append((label, p, h))\r\n",
    "  return l\r\n",
    "\r\n",
    "def getData(fileName):\r\n",
    "  data = getLPH(fileName=fileName)\r\n",
    "  Ps = [x[1] for x in data]\r\n",
    "  Hs = [x[2] for x in data]\r\n",
    "  # print(max(len(x.split()) for x in Ps))\r\n",
    "  # print(max(len(x.split()) for x in Hs))\r\n",
    "\r\n",
    "  LABELS = {'contradiction': 0, 'neutral': 1, 'entailment': 2}\r\n",
    "  Y = np.array([LABELS[x[0]] for x in data])\r\n",
    "  Y = np_utils.to_categorical(Y, len(LABELS))\r\n",
    "  \r\n",
    "  return Ps, Hs, Y\r\n",
    "\r\n",
    "training = getData('/content/drive/MyDrive/nli-datasets/snli/snli_1.0/snli_1.0_train.jsonl')\r\n",
    "validation = getData('/content/drive/MyDrive/nli-datasets/snli/snli_1.0/snli_1.0_dev.jsonl')\r\n",
    "test = getData('/content/drive/MyDrive/nli-datasets/snli/snli_1.0/snli_1.0_test.jsonl')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "tokenizer = Tokenizer(lower=False, filters='')\r\n",
    "tokenizer.fit_on_texts(training[0] + training[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(len(training[0])):\r\n",
    "\tprint(training[2][i] , \" : [\", training[0][i] , \"]<->[\", training[1][i] , \"]\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}