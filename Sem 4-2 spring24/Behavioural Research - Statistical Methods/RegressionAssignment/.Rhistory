theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +  # Color of tile borders
scale_fill_gradient(low = "white", high = "darkorange", name = "Correlation") +  # Color scale
labs(title = "Correlation Heatmap", x = "Features", y = "Features") +  # Labels
theme_classic() +  # Adjust theme for better readability
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +  # Color of tile borders
scale_fill_gradient(low = "white", high = "darkorange", mid="white" , name = "Correlation") +  # Color scale
labs(title = "Correlation Heatmap", x = "Features", y = "Features") +  # Labels
theme_classic() +  # Adjust theme for better readability
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +  # Color of tile borders
scale_fill_gradient(low = "white", high = "darkorange", name = "Correlation") +  # Color scale
labs(title = "Correlation Heatmap", x = "Features", y = "Features") +  # Labels
theme_classic() +  # Adjust theme for better readability
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# melted_data <- melt(correlation_matrix)
# ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
#   geom_tile(color = "white") +  # Color of tile borders
#   scale_fill_gradient(low = "white", high = "darkorange", name = "Correlation") +  # Color scale
#   labs(title = "Correlation Heatmap", x = "Features", y = "Features") +  # Labels
#   theme_classic() +  # Adjust theme for better readability
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
heatmap(correlation_matrix)
correlation_matrix <- cor(data[, 2:13])
correlation_matrix <- cor(data[, 2:13])
correlation_matrix
# melted_data <- melt(correlation_matrix)
# ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
#   geom_tile(color = "white") +  # Color of tile borders
#   scale_fill_gradient(low = "white", high = "darkorange", name = "Correlation") +  # Color scale
#   labs(title = "Correlation Heatmap", x = "Features", y = "Features") +  # Labels
#   theme_classic() +  # Adjust theme for better readability
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
heatmap(correlation_matrix)
melted_data <- melt(correlation_matrix)
ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +  # Color of tile borders
scale_fill_gradient(low = "white", high = "darkorange", name = "Correlation") +  # Color scale
labs(title = "Correlation Heatmap", x = "Features", y = "Features") +  # Labels
theme_classic() +  # Adjust theme for better readability
theme(axis.text.x = element_text(angle = 45, hjust = 1))
install.packages('psych')
# install.packages('psych')
library(psych)
parallel_results <- fa.parallel(my_data, nperm = 1000)
parallel_results <- fa.parallel(my_data)
parallel_results <- fa.parallel(data)
feature_data <- data[, 2:13]
feature_data
data
feature_data <- data[, 1:13]
feature_data
data
feature_data <- data[, 1:13]
feature_data
feature_data <- data[, 2:13]
feature_data
data
feature_data
feature_data <- data[, 2:13]
feature_data
feature_data <- data[, 1:13]
feature_data
feature_data <- data[, c("Alcohol","Malic","Ash","Alcalinity","Magnesium","Phenols","Flavanoids","Nonflavanoids","Proanthocyanins","Color","Hue","Dilution","Proline")]
feature_data
excel_path <- 'C:\\SSDFiles\\GitStuff\\iiith\\Sem 4-2 spring24\\Behavioural Research - Statistical Methods\\Assgn3\\wine.xlsx'
with_target_data <- read_excel(excel_path)
with_target_data
data <- data[, c("Alcohol","Malic","Ash","Alcalinity","Magnesium","Phenols","Flavanoids","Nonflavanoids","Proanthocyanins","Color","Hue","Dilution","Proline")]
data
correlation_matrix <- cor(data[, 2:13])
correlation_matrix
ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +  # Color of tile borders
scale_fill_gradient(low = "white", high = "darkorange", name = "Correlation") +  # Color scale
labs(title = "Correlation Heatmap", x = "Features", y = "Features") +  # Labels
theme_classic() +  # Adjust theme for better readability
theme(axis.text.x = element_text(angle = 45, hjust = 1))
correlation_matrix <- cor(data)
correlation_matrix
ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +  # Color of tile borders
scale_fill_gradient(low = "white", high = "darkorange", name = "Correlation") +  # Color scale
labs(title = "Correlation Heatmap", x = "Features", y = "Features") +  # Labels
theme_classic() +  # Adjust theme for better readability
theme(axis.text.x = element_text(angle = 45, hjust = 1))
data <- data[, c("Alcohol","Malic","Ash","Alcalinity","Magnesium","Phenols","Flavanoids","Nonflavanoids","Proanthocyanins","Color","Hue","Dilution","Proline")]
data
correlation_matrix <- cor(data)
correlation_matrix
melted_data <- melt(correlation_matrix)
ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +  # Color of tile borders
scale_fill_gradient(low = "white", high = "darkorange", name = "Correlation") +  # Color scale
labs(title = "Correlation Heatmap", x = "Features", y = "Features") +  # Labels
theme_classic() +  # Adjust theme for better readability
theme(axis.text.x = element_text(angle = 45, hjust = 1))
parallel_results <- fa.parallel(data)
install.packages('stats')
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
knitr::opts_chunk$set(echo = TRUE)
# install.packages('stats')
library(stats)
scaled_data <- scale(data)
scaled_data
# scaled_data <- scale(data)
# scaled_data
pca_result <- prcomp(data, scale. = TRUE)
pca_result
explained_variance <- pca_results$sdev^2 / sum(pca_results$sdev^2)
# scaled_data <- scale(data)
# scaled_data
pca_results <- prcomp(data, scale. = TRUE)
pca_results
explained_variance <- pca_results$sdev^2 / sum(pca_results$sdev^2)
explained_variance
# Transform data (optional)
pca_transformed_data <- my_data_scaled %*% pca_results$rotation[, 1:2]  # Select first 2 components
scaled_data <- scale(data)
scaled_data
scaled_data <- scale(data)
scaled_data
pca_results <- prcomp(data, scale. = TRUE)
pca_results
explained_variance <- pca_results$sdev^2 / sum(pca_results$sdev^2)
explained_variance
# Transform data (optional)
pca_transformed_data <- my_data_scaled %*% pca_results$rotation[, 1:2]  # Select first 2 components
# Transform data (optional)
pca_transformed_data <- scaled_data %*% pca_results$rotation[, 1:2]  # Select first 2 components
explained_variance[,1:3]
explained_variance[1:3]
pc1 <- pca_results$scores[, 1]
pc2 <- pca_results$scores[, 2]
# Create the scatter plot
ggplot(data.frame(PC1 = pc1, PC2 = pc2), aes(x = PC1, y = PC2)) +
geom_point(aes(color = ..pointcolour..), size = 3) +  # Adjust point size as desired
labs(title = "Scatter Plot of First Two Principal Components",
x = "PC1", y = "PC2") +
theme_classic()
knitr::opts_chunk$set(echo = TRUE)
rm(list = setdiff(ls(), lsf.str()))
# install.packages('readxl')
library(readxl)
# install.packages('ggplot2')
library(ggplot2)
# install.packages('reshape2')
library(reshape2)
# install.packages('stats')
library(stats)
# install.packages('psych')
library(psych)
excel_path <- 'C:\\SSDFiles\\GitStuff\\iiith\\Sem 4-2 spring24\\Behavioural Research - Statistical Methods\\Assgn3\\wine.xlsx'
with_target_data <- read_excel(excel_path)
with_target_data
data <- data[, c("Alcohol","Malic","Ash","Alcalinity","Magnesium","Phenols","Flavanoids","Nonflavanoids","Proanthocyanins","Color","Hue","Dilution","Proline")]
data <- with_target_data[, c("Alcohol","Malic","Ash","Alcalinity","Magnesium","Phenols","Flavanoids","Nonflavanoids","Proanthocyanins","Color","Hue","Dilution","Proline")]
data
knitr::opts_chunk$set(echo = TRUE)
rm(list = setdiff(ls(), lsf.str()))
# install.packages('readxl')
library(readxl)
# install.packages('ggplot2')
library(ggplot2)
# install.packages('reshape2')
library(reshape2)
# install.packages('stats')
library(stats)
# install.packages('psych')
library(psych)
excel_path <- 'C:\\SSDFiles\\GitStuff\\iiith\\Sem 4-2 spring24\\Behavioural Research - Statistical Methods\\Assgn3\\wine.xlsx'
with_target_data <- read_excel(excel_path)
with_target_data
data <- with_target_data[, c("Alcohol","Malic","Ash","Alcalinity","Magnesium","Phenols","Flavanoids","Nonflavanoids","Proanthocyanins","Color","Hue","Dilution","Proline")]
data
correlation_matrix <- cor(data)
correlation_matrix
melted_data <- melt(correlation_matrix)
ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +  # Color of tile borders
scale_fill_gradient(low = "white", high = "darkorange", name = "Correlation") +  # Color scale
labs(title = "Correlation Heatmap", x = "Features", y = "Features") +  # Labels
theme_classic() +  # Adjust theme for better readability
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# heatmap(correlation_matrix)
parallel_results <- fa.parallel(data)
scaled_data <- scale(data)
scaled_data
pca_results <- prcomp(data, scale. = TRUE)
pca_results
explained_variance <- pca_results$sdev^2 / sum(pca_results$sdev^2)
explained_variance[1:3]
pca_transformed_data <- scaled_data %*% pca_results$rotation[, 1:2]
pc1 <- pca_results$scores[, 1]
pc2 <- pca_results$scores[, 2]
# Create the scatter plot
ggplot(data.frame(PC1 = pc1, PC2 = pc2), aes(x = PC1, y = PC2)) +
geom_point(aes(color = ..pointcolour..), size = 3) +  # Adjust point size as desired
labs(title = "Scatter Plot of First Two Principal Components",
x = "PC1", y = "PC2") +
theme_classic()
# Create the scatter plot
ggplot(data.frame(PC1 = pc1, PC2 = pc2), aes(x = PC1, y = PC2)) +
geom_point(aes(color = ..pointcolour..), size = 3) +  # Adjust point size as desired
labs(title = "Scatter Plot of First Two Principal Components",
x = "PC1", y = "PC2") +
theme_classic()
pc1 <- pca_results$scores[, 1]
pc2 <- pca_results$scores[, 2]
pc1
pc2
pc1 <- pca_results$scores[, 1]
pc2 <- pca_results$scores[, 2]
scaled_data <- scale(data)
scaled_data
pca_results <- prcomp(data, scale. = TRUE)
pca_results
explained_variance <- pca_results$sdev^2 / sum(pca_results$sdev^2)
explained_variance[1:3]
explained_variance[0:3]
pca_transformed_data <- scaled_data %*% pca_results$rotation[, 1:2]
explained_variance[0:3]
explained_variance[1:3]
pca_transformed_data <- scaled_data %*% pca_results$rotation[, 1:2]
explained_variance[1:3]
explained_variance[0:3]
explained_variance[0:4]
explained_variance[1:3]
explained_variance[-1:3]
explained_variance[:3]
explained_variance[0:3]
pca_transformed_data <- scaled_data %*% pca_results$rotation[, 1:2]
pca_transformed_data
pca_results
pca_transformed_data
pca_results
pca_results$scores
pca_results[,1]
pca_results[1]
type(pca_transformed_data)
class(pca_transformed_data)
type_data <- with_target_data[,1]
type_data
pca_data_withtype <- cbind(type_data, pca_transformed_data)
pca_data_withtype
plot(pca_data_withtype)
plot(pca_data_withtype$PC1, pca_data_withtype$PC2, col=pca_data_withtype$Type)
observed_freq <- table(type_data)
length(type_data)
length(observed_freq)
expected_freq <- rep(n / length(observed_freq), length(observed_freq))
n <- length(type_data)
expected_freq <- rep(n / length(observed_freq), length(observed_freq))
expected_freq
length(observed_freq)
n <- length(type_data)
n
length(observed_freq)
n
length(type_data)
observed_freq
observed_freq
length(observed_freq)
observed_freq
observed_freq <- table(type_data)
n <- length(type_data)
expected_freq <- rep(n / length(observed_freq), length(observed_freq))
expected_freq
# Step 5: Perform the chi-square test
chi_sq_test <- chisq.test(observed_freq, p = expected_freq)
chi_sq_test
feature <- with_target_data$Alcohol # Replace 'feature_name' with the name of the feature column
# Step 2: Calculate quantiles
quantiles <- quantile(feature, probs = seq(0, 1, by = 0.01)) # Adjust 'by' parameter to desired granularity
# Step 3: Generate random samples based on the quantiles
distribution <- sample(quantiles, size = 1000, replace = TRUE) # Adjust 'size' parameter to desired sample size
# Step 4: Plot the distribution
hist(distribution, main = "Generated Distribution", xlab = "Values")
# Step 2: Calculate quantiles
quantiles <- quantile(feature, probs = seq(0, 1, by = 0.33)) # Adjust 'by' parameter to desired granularity
# Step 3: Generate random samples based on the quantiles
distribution <- sample(quantiles, size = 1000, replace = TRUE) # Adjust 'size' parameter to desired sample size
# Step 4: Plot the distribution
hist(distribution, main = "Generated Distribution", xlab = "Values")
# Step 2: Calculate quantiles
quantiles <- quantile(feature, probs = seq(0, 1, by = 1/3)) # Adjust 'by' parameter to desired granularity
# Step 3: Generate random samples based on the quantiles
distribution <- sample(quantiles, size = 1000, replace = TRUE) # Adjust 'size' parameter to desired sample size
# Step 4: Plot the distribution
hist(distribution, main = "Generated Distribution", xlab = "Values")
quantiles
# Step 2: Calculate quantiles
quantiles <- quantile(feature, probs = c(1/3, 2/3))
# Step 3: Divide the feature into three parts
top_third <- feature[feature > quantiles[2]]
middle_third <- feature[feature > quantiles[1] & feature <= quantiles[2]]
bottom_third <- feature[feature <= quantiles[1]]
top_third
middle_third
bottom_third
top_third
middle_third
bottom_third
quantiles
feature <- with_target_data$Alcohol
quantiles <- quantile(feature, probs = c(1/3, 2/3))
# Step 2: Categorize each row based on which third it belongs to
third_category <- cut(feature, breaks = c(-Inf, quantiles, Inf), labels = c("Bottom Third", "Middle Third", "Top Third"))
# Step 3: Create a contingency table
contingency_table <- table(wine_data$wine_type, third_category)
# Step 3: Create a contingency table
contingency_table <- table(with_target_data$Type, third_category)
# Display the contingency table
contingency_table
chisq.test(contingency_table)
#### Question 4.4
```{r}
#### Question 4.4
```{r}
chisq.test(contingency_table)
type_data <- with_target_data[,1]
type_data
pca_data_withtype <- cbind(type_data, pca_transformed_data)
pca_data_withtype
plot(pca_data_withtype$PC1, pca_data_withtype$PC2, col=pca_data_withtype$Type)
knitr::opts_chunk$set(echo = TRUE)
rm(list = setdiff(ls(), lsf.str()))
# install.packages('readxl')
library(readxl)
# install.packages('ggplot2')
library(ggplot2)
# install.packages('reshape2')
library(reshape2)
# install.packages('stats')
library(stats)
# install.packages('psych')
library(psych)
excel_path <- 'C:\\SSDFiles\\GitStuff\\iiith\\Sem 4-2 spring24\\Behavioural Research - Statistical Methods\\Assgn3\\wine.xlsx'
with_target_data <- read_excel(excel_path)
with_target_data
data <- with_target_data[, c("Alcohol","Malic","Ash","Alcalinity","Magnesium","Phenols","Flavanoids","Nonflavanoids","Proanthocyanins","Color","Hue","Dilution","Proline")]
data
correlation_matrix <- cor(data)
correlation_matrix
melted_data <- melt(correlation_matrix)
ggplot(melted_data, aes(x = Var1, y = Var2, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient(low = "white", high = "darkorange", name = "Correlation") +
labs(title = "Correlation Heatmap", x = "Features", y = "Features") +
theme_classic() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# heatmap(correlation_matrix)
parallel_results <- fa.parallel(data)
scaled_data <- scale(data)
scaled_data
pca_results <- prcomp(data, scale. = TRUE)
pca_results
explained_variance <- pca_results$sdev^2 / sum(pca_results$sdev^2)
explained_variance[0:3]
pca_transformed_data <- scaled_data %*% pca_results$rotation[, 1:2]
type_data <- with_target_data[,1]
type_data
pca_data_withtype <- cbind(type_data, pca_transformed_data)
pca_data_withtype
plot(pca_data_withtype$PC1, pca_data_withtype$PC2, col=pca_data_withtype$Type)
observed_freq <- table(type_data)
n <- length(type_data)
expected_freq <- rep(n / length(observed_freq), length(observed_freq))
expected_freq
chi_sq_test <- chisq.test(observed_freq, p = expected_freq)
chi_sq_test
feature <- with_target_data$Alcohol
quantiles <- quantile(feature, probs = c(1/3, 2/3))
# Step 2: Categorize each row based on which third it belongs to
third_category <- cut(feature, breaks = c(-Inf, quantiles, Inf), labels = c("Bottom Third", "Middle Third", "Top Third"))
# Step 3: Create a contingency table
contingency_table <- table(with_target_data$Type, third_category)
# Display the contingency table
contingency_table
chisq.test(contingency_table)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
rm(list = setdiff(ls(), lsf.str()))
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
setwd("C:/SSDFiles/GitStuff/iiith/Sem 4-2 spring24/Behavioural Research - Statistical Methods/RegressionAssignment") # change this to your working directory where you've put the data files, etc for this session
# Simulate data y <- b1x1 + b2x2 + b0 with Normally distributed residuals. You can assume sensible values for b1 b2 b0 as you please.
dat<-read.csv("housing.csv")
houselm <- lm(dat$median_house_value ~ dat$total_rooms + dat$median_income)
summary(houselm)
# Binary
mydata<-read.csv("binary.csv")
mydata$rank <- factor(mydata$rank)
fit <- glm(admit ~ gre + gpa + rank, data = mydata, family = "binomial")
summary(fit) # display results
confint(fit) # 95% CI for the coefficients
exp(confint(fit)) # 95% CI for exponentiated coefficients
fit <- glm(admit ~ gre + gpa + rank, data = mydata, family = "binomial")
summary(fit) # display results
confint(fit) # 95% CI for the coefficients
exp(coef(fit)) # exponentiated coefficients
exp(confint(fit)) # 95% CI for exponentiated coefficients
predict(fit, type="response") # predicted values
residuals(fit, type="deviance") # residuals
# Simulate data y <- b1x1 + b2x2 + b0 with Normally distributed residuals. You can assume sensible values for b1 b2 b0 as you please.
dat<-read.csv("housing.csv")
summary(houselm)
heatmap(dat)
dat
dat[,1:9]
dat[,0:9]
heatmap(dat[,0:9])
dat[,0:9]
dat[,0:8]
heatmap(dat[,0:9])
dat[,0:9]
# Binary
mydata<-read.csv("binary.csv")
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
install.packages("reshape")
install.packages("reshape")
library("reshape")
library("reshape")
install.packages("ggplot2")
install.packages("ggplot2")
library("ggplot2")
library("ggplot2")
dat[,0:9]
heatmap(dat[,0:9])
heatmap(data.matrix(dat[,0:9]))
heatmap_data <- data.matrix(dat[,0:9])
heatmap_data
heatmap(heatmap_data)
heatmap_data <- cor(dat[,0:9])
heatmap_data
heatmap(heatmap_data)
heatmap_data
heatmap(heatmap_data)
heatmap_data <- cor(dat[,0:9])
heatmap_data
heatmap_data <- cor(dat)
heatmap_data
heatmap_data <- cor(dat)
heatmap_data <- cor(dat[,0:9])
heatmap_data
dat[,0:9]
dat[,0:9]
heatmap_data
heatmap(heatmap_data)
heatmap_data <- cor(na.omit(dat[,0:9]))
heatmap_data
heatmap(heatmap_data)
nocat_dat <- data[,0:9]
nocat_dat <- dat[,0:9]
nocat_dat
nocat_dat
nocat_dat
nocat_dat
nocat_dat <- dat[,0:9]
nocat_dat
nocat_dat
install.packages("ggplot2")
library("ggplot2")
nocat_dat
nocat_dat
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
rm(list = setdiff(ls(), lsf.str()))
install.packages("reshape")
library("reshape")
install.packages("ggplot2")
library("ggplot2")
install.packages("GGally")
install.packages("ggplot2")
install.packages("reshape")
library("ggplot2")
rm(list = setdiff(ls(), lsf.str()))
setwd("C:/SSDFiles/GitStuff/iiith/Sem 4-2 spring24/Behavioural Research - Statistical Methods/RegressionAssignment") # change this to your working directory where you've put the data files, etc for this session
# setwd("~/Desktop/Work/BRSM_SP23/Lab")
# Simulate data y <- b1x1 + b2x2 + b0 with Normally distributed residuals. You can assume sensible values for b1 b2 b0 as you please.
dat<-read.csv("housing.csv")
houselm <- lm(dat$median_house_value ~ dat$total_rooms + dat$median_income)
summary(houselm)
# Binary
mydata<-read.csv("binary.csv")
mydata$rank <- factor(mydata$rank)
fit <- glm(admit ~ gre + gpa + rank, data = mydata, family = "binomial")
summary(fit) # display results
confint(fit) # 95% CI for the coefficients
exp(coef(fit)) # exponentiated coefficients
exp(confint(fit)) # 95% CI for exponentiated coefficients
predict(fit, type="response") # predicted values
residuals(fit, type="deviance") # residuals
nocat_dat <- dat[,0:9]
nocat_dat
install.packages("reshape")
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
nocat_dat <- dat[,0:9]
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
nocat_dat
nocat_dat <- dat[,0:9]
nocat_dat
nocat_dat
nocat_dat
nocat_dat
nocat_dat
nocat_dat
nocat_dat
