{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3622bff",
   "metadata": {},
   "source": [
    "# Assignment 2 - Text Retrieval - BIR & LSI  (23/09/2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d366cb29",
   "metadata": {},
   "source": [
    "## 1. Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e1e677",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "In this assignment, we introduce two other basic models in information retrieval namely, the <b><i>probabilistic</i></b> and <b><i>latent semantic indexing models</i></b>. The given tasks should help you understand better how to find a discriminative set of <b><i>index terms</i></b> (keywords) for collection of documents and queries. We study how to summarize the content of each document.\n",
    "In order to do this, we perform stemming by applying the <b><i>Porter algorithm</i></b> and visualize frequency of words using the <b><i>tag clouds</i></b> over the stems already obtained.\n",
    "\n",
    "Next, we extract the most informative words from documents based on the <b><i>term frequency-inverse documents frequency</i></b> (tf-idf) weighting scheme. Then, we complete the <b><i>probabilistic</i></b> and <b><i>latent semantic indexing models</i></b> to predict that the certain documents are relevant to the particular query.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bed0c2f",
   "metadata": {},
   "source": [
    "## 2. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2e2f3e",
   "metadata": {},
   "source": [
    "### 2.1 Probabilistic model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d649ab",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "    The <b><i>probabilistic model</i></b> is a simple retrieval model based on probabilistic framework. The idea is as follows. We consider a user query and a set of documents that contains only relevant documents for this query. We can think of this set as the ideal answer set. If there were given descriptors of ideal answer set, we would not have a problem with retrieving its documents. Querying process specifies the properties of an ideal answer set. In most cases, our problem is that we do not know exactly what these properties are. We know only that there are index terms whose semantic properties should be used to describe these properties. At the beginning, these properties are not known for particular query. We make an effort to guess what they could be. The initial values allows us to generate a preliminary probabilistic description of the ideal answer set. \n",
    "    \n",
    "We assume that there is a given user query $q$ and a document $d_{j}$ in the data base. We attempt to estimate the probability that the user will find the document $d_{j}$ as interesting. The fundamental assumption is that this probability of relevance depends on the query and the document representations only. Moreover, there is a ideal subset of all documents which the user chooses as the answer for this query.\n",
    "    \n",
    "For the <b><i>probabilistic model</i></b>, the index term weight variables are all binary. A query $q$ is a subset of index terms. Let $R$ be the set of initially guessed documents to be relevant. Let \n",
    "$\\bar{R}$ be the complement set of R. It means that $\\bar{R}$ contains all non-relevant documents in the collection. Let $P(R|d_{j})$ be the probability that the document $d_{j}$ is relevant to the query $q$ and $P(\\bar{R}|d_{j})$ be the probability that the document $d_{j}$ is non-relevant to the query $q$. The similarity measure $sim(d_{j},q)$ between the document $d_{j}$ and the query $q$ is defined as the ratio\n",
    "\\begin{equation}\n",
    "sim(d_{j},q)= \\frac{P(R|d_{j})}{P(\\bar{R}|d_{j})}.\n",
    "\\end{equation}\n",
    "    \n",
    "Applying <b><i>Bayes' rule</i></b>, we get the following expression\n",
    "\\begin{equation}\n",
    "sim(d_{j},q)= \\frac{P(d_{j}|R)\\cdot P(R)}{P(d_{j}|\\bar{R})\\cdot P(\\bar{R})},\n",
    "\\end{equation}\n",
    "    \n",
    "where $P(d_{j}|R)$ corresponds to the probability of randomly selecting the document $d_{j}$ from the set $R$ and $P(R)$ corresponds to the probability that a selected  document is relevant.\n",
    "$P(d_{j}|\\bar{R})$ and $P(\\bar{R})$ are analogous and complementary.\n",
    "    Assuming independence of <b><i>index terms</i></b> and taking logarithms, we can finally write:\n",
    "    \n",
    "\\begin{equation}\n",
    "sim(d_{j},q)=\\sum_{i=1}^{k} w_{iq} \\cdot w_{ij} \\cdot \\left( \\log \\frac{P(t_{i}|R)}{1-P(t_{i}|R)} +\\log \\frac{1-P(t_{i}|\\bar{R})}{P(t_{i}|\\bar{R})} \\right),\n",
    "\\end{equation}\n",
    "    \n",
    "where  $P(t_{i}|R)$ corresponds to the probability that <b><i>index term</i></b> $t_{i}$ is present in a document randomly selected from the set $R$. The probabilities associated with the set $\\bar{R}$ have meanings that are analogous to the ones just described.\n",
    "    \n",
    "Since we do not know the set $R$ at the beginning, it is necessary to choose a method for initially  computing the probabilities $P(t_{i}|R)$ and $P(t_{i}|\\bar{R})$. Now, we discuss some alternative approaches to computing them.\n",
    "    \n",
    "We only consider one method in which we assume initially that $P(t_{i}|R)$ is constant for all index terms, e.g. equal $0.5$ and  the distribution of <b><i>index terms</i></b> among non-relevant documents can be approximated by the distribution of index terms among all documents in the collection. These two assumptions provide the formulas:\n",
    "    \n",
    "\\begin{equation}\n",
    "P(t_{i}|R)=0.5, P(t_{i}|\\bar{R})=\\frac{n_{i}}{N},\n",
    "\\end{equation}\n",
    "    \n",
    "where $N$ is the total number of documents, and $n_{i}$ is the number of documents in which the\n",
    "term $t_{i}$ appears. Based on it, we retrieve initial probabilistic <b><i>ranking</i></b> that is improved as follows. \n",
    "    \n",
    "Let $V$ be a subset of the documents initially retrieved and ranked by the probabilistic model, for instance, the top $r$ ranked documents where $r$ is a certain <b><i>threshold</i></b>. Next, let $V_{i}$ be the subset of $V$ composed of the documents in $V$ which contain the <b><i>index term</i></b> $t_{i}$. \n",
    "    \n",
    "Further, we can improve recursively our initial guesses values of $P(t_{i}|R)$ and $P(t_{i}|\\bar{R})$. This can be accomplished with satisfying the following assumptions. We can approximate $P(t_{i}|R)$ by the distribution of index term $t_{i}$ among the documents retrieved so far, and we can approximate $P(t_{i}|\\bar{R})$ by considering that all the non-retrieved documents are not relevant. With theses assumptions, we can express updating rules as follows:\n",
    "    \n",
    "\\begin{equation}\n",
    "P(t_{i}|R):=\\frac{|V_{i}|}{|V|}, P(t_{i}|\\bar{R}):=\\frac{n_{i}-|V_{i}|}{N-|V|}.\n",
    "\\end{equation}\n",
    "    \n",
    "The last formulas for $P(t_{i}|R)$ and $P(t_{i}|\\bar{R})$ have a problem for small values of $V$ and $V_{i}$ which appears in practice. To solve it, we can add some adjustment factor and obtain:\n",
    "    \n",
    "\\begin{equation}\n",
    "P(t_{i}|R):=\\frac{|V_{i}|+0.5}{|V|+1}, P(t_{i}|\\bar{R}):=\\frac{n_{i}-|V_{i|}+0.5}{N-|V|+1}.\n",
    "\\end{equation}\n",
    "    \n",
    "An alternative is to take the fraction $\\frac{n_{i}}{N}$ as the adjustment factor which yields:\n",
    "\n",
    "\\begin{equation}\n",
    "P(t_{i}|R):=\\frac{|V_{i}|+\\frac{n_{i}}{N}}{|V|+1},  P(t_{i}|\\bar{R}):=\\frac{n_{i}-|V_{i}|+\\frac{n_{i}}{N}}{N-|V|+1},\n",
    "\\end{equation}\n",
    "    \n",
    "where $|\\cdot|$ means a number of set elements. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d68bfe",
   "metadata": {},
   "source": [
    "### 2.2 Latent semantic indexing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e3858e",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "The idea of <b><i>latent semantic indexing model</i></b> is that the process of matching documents to a given query could be done based on concept matching instead of index term matching. This would allow us to retrieve the documents even when they are not indexed by query index terms. For example, a document could be retrieved because it shares concepts with another document which is relevant to the given query. <b><i>Latent semantic indexing model</i></b> addresses these issues. This approach maps each document and query vector into a lower dimensional space which is associated with concepts. The reduced space may be better to retrieve information than the original one.\n",
    "    \n",
    "Let $k$ be the number of index terms in the collection of documents and $N$ be the the total number of documents. Define $M$ as a matrix with $k$ rows and $N$ columns. Each element $M_{ij}$ of this matrix is assigned a weight $w_{ij}$ associated with the index term $t_{i}$ and the document $d_{j}$. The weight $w_{ij}$ could be generated using <b><i>tf-idf </i></b> weighting technique.\n",
    " \n",
    "<b><i>Latent semantic indexing model</i></b> proposes to decompose the <b><i>term-document</i></b> matrix $M$ using <b><i>singular value decomposition</i></b> as follows:\n",
    "    \n",
    "\\begin{equation}\n",
    "M=S \\cdot  \\Delta \\cdot D^{T}.\n",
    "\\end{equation}\n",
    "    \n",
    "Matrix $S$ is the matrix of eigenvectors obtained from $M\\cdot M^{T}$. Matrix $D$ is the matrix of eigenvectors derived from $ M^{T} \\cdot M$. Matrix $ \\Delta$ is an $r \\times r$ diagonal matrix of singular values where $r=min(k,N)$ is the rank of $M$.\n",
    "    \n",
    "Consider now only the $l$ largest singular values of $ \\Delta$ and keep them along with their corresponding columns in $S$ and $D$, respectively. The result is matrix $M_{l}$ given by:\n",
    "    \n",
    "\\begin{equation}\n",
    "M_{l}=S_{l} \\cdot  \\Delta_{l} \\cdot D_{l}^{T},\n",
    "\\end{equation}\n",
    "    \n",
    "where $l$, $l<r$, is the dimensionality of the reduced concept space. The selection of a value for $l$ tries to balance two opposing effects. It means that $l$ should be large enough to fit all  the  structure in the real data. On the other hand, it should be small enough to filter out non-relevant details of data.\n",
    "    \n",
    "The relation between any two documents in the reduced space of dimensionality $l$ can be derived from the matrix $M_{l}^{T} \\cdot M_{l}$, where element $(i,j)$ quantifies the relationship between documents  $d_{i}$ and  $d_{j}$.\n",
    "    \n",
    "To rank documents with regard to a given user query, we consider the query as a document in the original matrix $M$. \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbd5adc",
   "metadata": {},
   "source": [
    "## 3. List of tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b744581c",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "    \n",
    "Implement the below tasks **in sequence**. For any task that requires additional explanation, include it in your report. All 5 python files as detailed in section 4.1 are required to be submitted. You may submit jupyter notebooks as well. Also include a Report.pdf with your submission. <br>\n",
    "    \n",
    "Note that Tasks 1-3 can be reused from the last assignment as all models function on the same weighting scheme (apart from Boolean). Further, for few parts of tasks such as choosing top $p$ stems, providing $s$ queries to the system, etc., utilize the same techniques of corresponding parts from assignment 1.\n",
    "    \n",
    "<ol>\n",
    "    <li>Use e.g. 15 articles from <i>NASA</i> corpus to obtain raw data and apply <i>tokenisation</i>.</li> \n",
    "    <li> Perform stemming using <i>Porter algorithm</i>. </li>\n",
    "    <li> Compute <i>term frequency </i>$tf_{ij}$ and <i>tf-idf</i> $w_{ij}$ for each document with and without removal of stop words.</li>\n",
    "    <li> Build <i>probabilistic</i> (test different updating rules) and <i>latent semantic indexing model</i> based on top $p$ stems according to <i>tf-idf</i> for each document, without removal of stop words and then provide $s$ queries to each IR system. Compare rankings of relevant articles.</li>\n",
    "    <li>Use the <i>term frequency</i> $tf_{ij}$ and <i>tf-idf</i> $w_{ij}$ you computed earlier for each document after removing stop words. Choose the top $p$ stems according to <i>tf-idf</i> for each document. Based on these, build new <i>probabilistic</i> (test different updating rules) and <i>latent semantic indexing model</i>. Then, provide $s$ the same queries to each IR system. Compare current rankings of relevant articles with obtained before.</li>\n",
    "    <li>Provide final remarks and conclusions, compare current results with <i>boolean</i> and <i>vector models</i> (Assignment 1).</li>\n",
    "</ol>\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57890888",
   "metadata": {},
   "source": [
    "## 4. Practical requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754139c3",
   "metadata": {},
   "source": [
    "### 4.1 Implementation of required functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f623d5f8",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "Note that these functions should be compatible with those developed in Assignment 1.\n",
    "<ul>\n",
    "    <li><b>TermDocumentMatrixProbModel.py</b> reads all <i>.txt</i> from a specifed directory (where your corpus is), creates a boolean representation for each document, and puts them together into a term-document matrix.</li>\n",
    "    <li><b>TermDocumentMatrixLatentSemanticIndexing.py</b> reads all <i>.txt</i> from a specifed directory (where your corpus is), creates a latent semantic indexing representation for all documents and queries, and puts them together into a term-document matrix.</li>\n",
    "    <li><b>RankingProbModel.py</b> compares similarity between a given query and the documents, and returns similarity values and filenames of the top $N$ relevant documents.</li>\n",
    "    <li><b>RankingLatentSemanticIndexing.py</b> compares similarity between a given query and the documents, and returns similarity values and filenames of the top $N$ relevant documents. Note that a query is treated as a short document in term-document matrix.</li>\n",
    "    <li><b>queryBooleanRepresentationProbModel.py</b> returns a boolean representation of a query for probabilistic model.</li>\n",
    "</ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e124353",
   "metadata": {},
   "source": [
    "### 4.2 Required evaluation corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c6796d",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "\n",
    "<b>NASA</b> collection covers 141 short articles in <b>nasa.tar.gz</b> file.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e9563",
   "metadata": {},
   "source": [
    "## 5. Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8945d9",
   "metadata": {},
   "source": [
    "### 5.1 Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443effb",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "\n",
    "The assessment is based on your report and code. Your PDF report should include all experimental results, your answers to all questions, and your analysis and comments of the experimental results. Please try to detail the report by giving examples and conclusions.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4459d06a",
   "metadata": {},
   "source": [
    "<font size=\"3\">\n",
    "Compress the 5 python files and the Report.pdf file into &lt;RollNumber&gt;_Assignment2.zip, which you should submit on Moodle.<br>\n",
    "\n",
    "An in person evaluation will be conducted, in which you are required to walk us through your code and report.<br>\n",
    "\n",
    "Please note that the deadline is **7th October 2023**, and **will not be extended.** Use moodle for all queries.<br><br> \n",
    "    \n",
    "**Total marks** - 25 marks. <br>\n",
    "- **Preprocessing** (1 mark)<br>\n",
    "- **TF-IDF** (2 marks)<br>\n",
    "- **Probabilistic model** (8 marks)<br>\n",
    "- **Latent semantic indexing model** (8 marks)<br>\n",
    "- **Report and explanations** (6 marks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2022.05-py39",
   "language": "python",
   "name": "conda-env-anaconda-2022.05-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
